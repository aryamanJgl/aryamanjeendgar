#+title: Current Stack of Interesting Literature

| [[file:index.org::about][About]] | [[file:blog.org][Blog]] | [[file:cv.org][CV]] | [[file:PaperReviews.org][Papers to Read]] |

1. *Amir Beck's* excellent text: /First-Order Methods In Optimization/. A really well-written text bringing together a wealth of material on fundamental optimization theory and first order convex optimization algorithms
2. *Nemirovski's* recent update to his classical, [[https://www2.isye.gatech.edu/~nemirovs/LMCOLN2022Fall.pdf][/Lectures on Modern Convex Optimization/]]. It's first three chapters are the natural next step after internalizing the [[https://docs.mosek.com/modeling-cookbook/index.html][/MOSEK modeling cookbook/]] for understanding conic optimization!
3. [[https://www.nicolasboumal.net/book/][/An introduction to optimization on smooth manifolds/]]: The title! Written by Nicolas Boumal (current maintaner of [[https://github.com/pymanopt/pymanopt][PyManOPT]]!)
4. [[https://arxiv.org/abs/1803.00567][/Computational Optimal Transport/]]: A reall well-written introduction to Optimal Transport for those with a solid mathematical background (co-authored by none other than /Marco Cuturi/!)
5. [[https://arxiv.org/abs/1705.00812][Semidefinite approximations of the matrix logarithm]]: Find (an evolving) commentary on the paper [[file:blog.org::FSP,review][*HERE*]]
6. [[https://arxiv.org/abs/1710.10044][Distributional Reinforcement Learning with Quantile Regression]] --- for a comprehensive introduction to distributional RL see [[https://www.distributional-rl.org/][HERE]]
7. [[https://arxiv.org/abs/2106.11565][Practical Near Neighbour Search via Group testing]] --- really cool work that uses the notion of [[https://www.eecs.harvard.edu/~michaelm/postscripts/alenex2006.pdf][Distance Sensitive Bloom Filters]] coupled with ideas from [[https://arxiv.org/abs/1902.06002][Group Testing]] to devise a really efficient framework for the approximate nearest neighbor search problem (they outperform FAISS by multiple factors!)
8. Numerical Linear Algebra, /Lloyd N. Trefethen and David Bau III/: Need to iron out my understanding of NLA, and this classical text is the best there is for a (relatively) self-contained course! Can then graduate to using /Matrix Computations/ as a reference for all my LA needs like every sane applied mathematician XD.
9. [[https://arxiv.org/abs/1909.05207?context=cs.LG][Introduction to Online Convex Optimization]]: Elad Hazan's text on OCO. Online learning is really cool, and I wanna learn about it!
10. [[https://arxiv.org/abs/1405.4980][Convex Optimization: Algorithms and Complexity]]: A beautiful monograph on the algorithmics of Convex optimization, plan on reading in conjunction with Boyd's theory portion.
11. [[https://arxiv.org/abs/1712.07897][Non-Convex optimization for Machine Learning]]: Prateek Jain's monograph on some broad ideas in non-convex optimization, really exciting stuff!
12. [[https://docs.google.com/viewer?url=https://raw.githubusercontent.com/tengyuma/cs229m_notes/main/master.pdf][Tengyu Ma's StatML notes]]: Already have some background in learning theory from Shai's excellent text --- plan to use Ma's notes as a reference while going through the above stuff, his notes also have some material on NTK ideas!
13. A User's guide to Measure Theoretic Probability Theory, /David Pollard/: An amazing text giving a self-contained tour of MTPT (ought to probably be sufficient for wannabe applied mathematician like me XD).
